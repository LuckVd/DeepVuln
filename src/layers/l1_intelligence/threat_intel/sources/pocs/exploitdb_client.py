"""ExploitDB client for PoC/Exploit data."""

import csv
import re
from collections.abc import AsyncIterator
from datetime import datetime
from io import StringIO
from typing import Any

import aiohttp

from src.core.logger.logger import get_logger
from src.layers.l1_intelligence.threat_intel.core.data_models import PoCInfo

logger = get_logger(__name__)


class ExploitDBClient:
    """Exploit-DB client for exploit/PoC data.

    ExploitDB provides a CSV file with all exploits that can be downloaded
    and parsed for CVE correlations.

    CSV URL: https://gitlab.com/exploit-database/exploitdb/-/raw/main/files_csv_exploits.csv
    Website: https://www.exploit-db.com/
    """

    CSV_URL = "https://gitlab.com/exploit-database/exploitdb/-/raw/main/files_csv_exploits.csv"
    BASE_URL = "https://www.exploit-db.com"

    def __init__(self) -> None:
        """Initialize ExploitDB client."""
        self._cache: dict[str, PoCInfo] = {}
        self._cve_index: dict[str, list[str]] = {}  # CVE -> [poc_ids]
        self._last_sync: datetime | None = None

    async def sync(self) -> int:
        """Sync ExploitDB CSV data.

        Returns:
            Number of exploits synced.
        """
        logger.info("Syncing ExploitDB data...")

        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(self.CSV_URL) as response:
                    if response.status != 200:
                        raise Exception(f"HTTP {response.status}")

                    content = await response.text()

            # Parse CSV
            self._cache.clear()
            self._cve_index.clear()

            reader = csv.DictReader(StringIO(content))
            count = 0

            for row in reader:
                try:
                    poc = self._parse_row(row)
                    if poc:
                        self._cache[poc.poc_id] = poc

                        # Index by CVE
                        for cve_id in poc.cve_ids:
                            if cve_id not in self._cve_index:
                                self._cve_index[cve_id] = []
                            self._cve_index[cve_id].append(poc.poc_id)

                        count += 1

                except Exception as e:
                    logger.debug(f"Failed to parse row: {e}")
                    continue

            self._last_sync = datetime.now()
            logger.info(f"Synced {count} ExploitDB entries")

            return count

        except Exception as e:
            logger.error(f"Failed to sync ExploitDB: {e}")
            raise

    def _parse_row(self, row: dict[str, str]) -> PoCInfo | None:
        """Parse a CSV row into PoCInfo.

        Args:
            row: CSV row dictionary.

        Returns:
            PoCInfo or None if invalid.
        """
        exploit_id = row.get("id", "").strip()
        if not exploit_id:
            return None

        # Extract CVE IDs from codes field
        codes = row.get("codes", "")
        cve_ids = self._extract_cves(codes)

        # Parse date
        published_date = None
        date_str = row.get("date", "")
        if date_str:
            try:
                published_date = datetime.strptime(date_str, "%Y-%m-%d")
            except ValueError:
                pass

        # Determine PoC type
        poc_type = row.get("type", "poc").lower()
        if "dos" in poc_type:
            poc_type = "dos"
        elif "local" in poc_type:
            poc_type = "local"
        elif "remote" in poc_type:
            poc_type = "remote"
        elif "webapps" in poc_type:
            poc_type = "webapp"

        return PoCInfo(
            poc_id=f"EDB-{exploit_id}",
            source="exploitdb",
            cve_ids=cve_ids,
            title=row.get("description", "").strip(),
            poc_type=poc_type,
            code_url=f"{self.BASE_URL}/exploits/{exploit_id}",
            code_local_path=row.get("file", ""),
            language=row.get("platform", ""),
            author=row.get("author", ""),
            published_date=published_date,
            verified=row.get("verified", "") == "1",
        )

    def _extract_cves(self, codes: str) -> list[str]:
        """Extract CVE IDs from codes field.

        Args:
            codes: Codes string (may contain multiple CVEs, OSVDB, etc.).

        Returns:
            List of CVE IDs.
        """
        if not codes:
            return []

        # Match CVE-YYYY-NNNN or CVE-YYYY-NNNNN
        pattern = r"CVE-\d{4}-\d{4,7}"
        matches = re.findall(pattern, codes, re.IGNORECASE)

        return [m.upper() for m in matches]

    def get_poc(self, poc_id: str) -> PoCInfo | None:
        """Get a PoC by ID.

        Args:
            poc_id: PoC identifier (e.g., EDB-12345).

        Returns:
            PoCInfo or None.
        """
        return self._cache.get(poc_id)

    def get_pocs_for_cve(self, cve_id: str) -> list[PoCInfo]:
        """Get all PoCs for a CVE.

        Args:
            cve_id: CVE identifier.

        Returns:
            List of PoCInfo objects.
        """
        poc_ids = self._cve_index.get(cve_id.upper(), [])
        return [self._cache[poc_id] for poc_id in poc_ids if poc_id in self._cache]

    def search(self, query: str) -> list[PoCInfo]:
        """Search PoCs by keyword.

        Args:
            query: Search query.

        Returns:
            List of matching PoCInfo objects.
        """
        query_lower = query.lower()
        results = []

        for poc in self._cache.values():
            if (
                query_lower in poc.title.lower()
                or (poc.description and query_lower in poc.description.lower())
                or query_lower in poc.poc_type.lower()
                or (poc.language and query_lower in poc.language.lower())
            ):
                results.append(poc)

        return results

    def get_by_platform(self, platform: str) -> list[PoCInfo]:
        """Get PoCs for a specific platform.

        Args:
            platform: Platform name (e.g., "php", "windows", "linux").

        Returns:
            List of PoCInfo objects.
        """
        platform_lower = platform.lower()
        return [
            poc
            for poc in self._cache.values()
            if poc.language and platform_lower in poc.language.lower()
        ]

    def get_by_type(self, poc_type: str) -> list[PoCInfo]:
        """Get PoCs by type.

        Args:
            poc_type: Type (remote, local, dos, webapp).

        Returns:
            List of PoCInfo objects.
        """
        return [
            poc
            for poc in self._cache.values()
            if poc.poc_type == poc_type.lower()
        ]

    async def iter_all(self) -> AsyncIterator[PoCInfo]:
        """Iterate over all cached PoCs.

        Yields:
            PoCInfo objects.
        """
        for poc in self._cache.values():
            yield poc

    def get_stats(self) -> dict[str, Any]:
        """Get statistics about cached data.

        Returns:
            Statistics dictionary.
        """
        types: dict[str, int] = {}
        platforms: dict[str, int] = {}
        cve_count = 0

        for poc in self._cache.values():
            # Count by type
            t = poc.poc_type or "unknown"
            types[t] = types.get(t, 0) + 1

            # Count by platform
            if poc.language:
                platforms[poc.language] = platforms.get(poc.language, 0) + 1

            # Count CVEs
            if poc.cve_ids:
                cve_count += len(poc.cve_ids)

        return {
            "total_exploits": len(self._cache),
            "with_cve": len(self._cve_index),
            "total_cve_refs": cve_count,
            "verified_count": sum(1 for p in self._cache.values() if p.verified),
            "types": dict(sorted(types.items(), key=lambda x: x[1], reverse=True)[:10]),
            "platforms": dict(sorted(platforms.items(), key=lambda x: x[1], reverse=True)[:10]),
            "last_sync": self._last_sync.isoformat() if self._last_sync else None,
        }

    @property
    def cache_size(self) -> int:
        """Get number of cached exploits."""
        return len(self._cache)
